{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvVgTwZ9xYp+o+b9gdbS3D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1.&nbsp;Libraries"],"metadata":{"id":"XD2a4f2g4Xe-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GsIMwClJ4NP-"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import datetime as dt\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, LSTM"]},{"cell_type":"markdown","source":["# 2.&nbsp;Data Preprocessing"],"metadata":{"id":"GFTFaBo24dKK"}},{"cell_type":"code","source":["# Load Data\n","florida = pd.read_csv('florida_file_.csv')\n","florida.head()\n","florida.tail(5)\n","florida[\"Date\"] = pd.to_datetime(florida[\"Date\"])\n","\n","florida = florida[[\"Date\", \"Avg_Temp\"]]\n","florida = florida.fillna(florida.bfill())\n","florida.columns = ['Date', 'Avg_Temp']\n","\n","train = florida[:-225]\n","len(train)\n","test = florida[-225:]\n","len(test)\n","train_dates = pd.to_datetime(train['Date'])\n","test_dates  = pd.to_datetime(test['Date'])\n","\n","# Prepare Data\n","scaler = MinMaxScaler(feature_range=(0,1))\n","scaled_data = scaler.fit_transform(train['Avg_Temp'].values.reshape(-1,1))\n","\n","prediction_days = 225\n","\n","x_train = []\n","y_train = []\n","\n","for x in range(prediction_days, len(scaled_data)):\n","    x_train.append(scaled_data[x-prediction_days:x, 0])\n","    y_train.append(scaled_data[x, 0])\n","\n","\n","x_train, y_train = np.array(x_train), np.array(y_train)\n","x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"],"metadata":{"id":"AsDOqqSK5JWS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3.&nbsp;LSTM Model"],"metadata":{"id":"XYBEhyEs5Tgc"}},{"cell_type":"code","source":["# Build The Model\n","model = Sequential()\n","\n","model.add(LSTM(units =128, activation='relu', return_sequences=True, input_shape = (x_train.shape[1],1)))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units =128, activation='relu', return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units =128, activation='relu', return_sequences=False))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=1)) # Prediction of the next value\n","\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","model.summary()\n","\n","history = model.fit(x_train, y_train, epochs = 25, batch_size=32, validation_split=0.1)\n","\n","\n","plt.plot(history.history['loss'], label = 'Training Loss')\n","plt.plot(history.history['val_loss'], label = 'Validation Loss')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"rI_Pa2Vk5Y8l"},"execution_count":null,"outputs":[]}]}